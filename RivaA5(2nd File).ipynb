{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rivarola.Ester_A5 \n",
    "\n",
    "(This code was run with the help of a tutor on Chegg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#import all required packages\n",
    "\n",
    "import pandas as pd\n",
    "import nltk.stem\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn import naive_bayes\n",
    "from sklearn import tree\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_______________________________________________________________________________________________________________________\n",
    "Hotel 1:\n",
    "\n",
    "\n",
    "Doubletree By Hilton \n",
    "\n",
    "341 West 36th Street, New York City, NY 10018-640\n",
    "    \n",
    "Rating: 3.5\n",
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>The hotel is in a good location, and the staff...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Me and my husband booked this hotel from a caf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "      <td>Normally I find success with Hilton properties...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "      <td>We had a top floor (26th) room. The issue was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.0</td>\n",
       "      <td>The hotel is very close to time square and Jav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0     2.0  The hotel is in a good location, and the staff...\n",
       "1     5.0  Me and my husband booked this hotel from a caf...\n",
       "2     2.0  Normally I find success with Hilton properties...\n",
       "3     2.0  We had a top floor (26th) room. The issue was ...\n",
       "4     3.0  The hotel is very close to time square and Jav..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# in 587, we learned how to use pandas and numpy to read csv files \n",
    "\n",
    "df=pd.read_csv(\"Rivarola.Ester-A5_Hotel1.csv\",usecols=[0,1],names=[\"rating\",\"review\"],encoding = \"ISO-8859-1\")\n",
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing all the rating values as target variable. We are converting the rating in string format as it is a categorical variable and would be used as a target value to the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "target=[]\n",
    "for i in df.rating:\n",
    "    if(i==1):\n",
    "        target.append(\"1\")\n",
    "    elif(i==2):\n",
    "        target.append(\"2\")\n",
    "    elif(i==3):\n",
    "        target.append(\"3\")\n",
    "    elif(i==4):\n",
    "        target.append(\"4\")\n",
    "    else:\n",
    "        target.append(\"5\")\n",
    "y=np.array(target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next step involves the preprocessing of the review data. Preprocessing steps involve removing the stop words, stemming all the words, and using Tfidf to remove all the insignificant words(words of my tutor on Chegg.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer=super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc:(english_stemmer.stem(w) for w in analyzer(doc))\n",
    "vectorizer=StemmedTfidfVectorizer(min_df=1,stop_words='english',decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=vectorizer.fit_transform(df.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(350,)\n",
      "(350, 2327)\n"
     ]
    }
   ],
   "source": [
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data set into train and test data. We will train th emodel using the train dataset. Train and test are 80% and 20% respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test=train_test_split(X,y,random_state=70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create two models, one using the Naive Bayes and other using the Decision tree. We will later compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "naive_clf=naive_bayes.MultinomialNB()\n",
    "naive_clf=naive_clf.fit(X_train,y_train)\n",
    "dec_clf=tree.DecisionTreeClassifier()\n",
    "dec_clf=dec_clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create confusion matrix to get an insight of performance of both the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  1 13  4  0]\n",
      " [ 1  0  6  3  0]\n",
      " [ 0  1 14  9  0]\n",
      " [ 0  0  4 14  0]\n",
      " [ 0  0  4  9  3]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "y_naivepred=naive_clf.predict(X_test)\n",
    "y_decpred=dec_clf.predict(X_test)\n",
    "naivematrix=confusion_matrix(y_test, y_naivepred)\n",
    "decmatrix=confusion_matrix(y_test, y_decpred)\n",
    "print(naivematrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[12  3  1  4  0]\n",
      " [ 2  2  3  3  0]\n",
      " [ 1  7  7  8  1]\n",
      " [ 0  1  3 10  4]\n",
      " [ 0  1  5  7  3]]\n"
     ]
    }
   ],
   "source": [
    "print(decmatrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finding the values of True Positive, True Negative, False Positive and False Negative of both the models using the corresponding confusion matrices. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP-Naive Bayes\n",
      "[2, 0, 14, 14, 3]\n",
      "TP-Decision Tree\n",
      "[12, 2, 7, 10, 3]\n",
      "FP-Naive Bayes\n",
      "[1, 2, 27, 25, 0]\n",
      "FP-Decision Tree\n",
      "[3, 12, 12, 22, 5]\n",
      "TN-Naive Bayes\n",
      "[31, 33, 19, 19, 30]\n",
      "TN-Decision Tree\n",
      "[22, 32, 27, 24, 31]\n",
      "FN-Naive Bayes\n",
      "[18, 10, 10, 4, 13]\n",
      "FN-Decision Tree\n",
      "[8, 8, 17, 8, 13]\n"
     ]
    }
   ],
   "source": [
    "naive_tp=[naivematrix[i][i] for i in range(5)]\n",
    "dec_tp=[decmatrix[i][i] for i in range(5)]\n",
    "\n",
    "naive_fp=[]\n",
    "dec_fp=[]\n",
    "i=0\n",
    "while(i<5):\n",
    "    naive_sums=0\n",
    "    dec_sums=0\n",
    "    j=0\n",
    "    while(j<5):\n",
    "        if(i!=j):\n",
    "            naive_sums+=naivematrix[j][i]\n",
    "            dec_sums+=decmatrix[j][i]\n",
    "        j+=1\n",
    "    naive_fp.append(naive_sums)\n",
    "    dec_fp.append(dec_sums)\n",
    "    i+=1\n",
    "\n",
    "naivediag=0\n",
    "decdiag=0\n",
    "i=0\n",
    "while(i<5):\n",
    "    naivediag+=naivematrix[i][i]\n",
    "    decdiag+=decmatrix[i][i]\n",
    "    i+=1\n",
    "\n",
    "naive_tn=[naivediag-naivematrix[i][i] for i in range(5)]\n",
    "dec_tn=[decdiag-decmatrix[i][i] for i in range(5)]\n",
    "\n",
    "naive_fn=[]\n",
    "dec_fn=[]\n",
    "i=0\n",
    "while(i<5):\n",
    "    naive_sums=0\n",
    "    dec_sums=0\n",
    "    j=0\n",
    "    while(j<5):\n",
    "        if(i!=j):\n",
    "            naive_sums+=naivematrix[i][j]\n",
    "            dec_sums+=decmatrix[i][j]\n",
    "        j+=1\n",
    "    naive_fn.append(naive_sums)\n",
    "    dec_fn.append(dec_sums)\n",
    "    i+=1\n",
    "\n",
    "print(\"TP-Naive Bayes\")\n",
    "print(naive_tp)\n",
    "print(\"TP-Decision Tree\")\n",
    "print(dec_tp)\n",
    "print(\"FP-Naive Bayes\")\n",
    "print(naive_fp)\n",
    "print(\"FP-Decision Tree\")\n",
    "print(dec_fp)\n",
    "print(\"TN-Naive Bayes\")\n",
    "print(naive_tn)\n",
    "print(\"TN-Decision Tree\")\n",
    "print(dec_tn)\n",
    "print(\"FN-Naive Bayes\")\n",
    "print(naive_fn)\n",
    "print(\"FN-Decision Tree\")\n",
    "print(dec_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the values of precision, recall and F1-Score for both the models.\n",
    "\n",
    "Using the formulas below:\n",
    "\n",
    "Precision=True Positive/(True Positive + False Positive)\n",
    "\n",
    "Recall=True Positive/(True Positive + False Negative)\n",
    "\n",
    "F1 Score=(2*True Positive)/(2*True Positive + False Positive + False Negative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating Naive Bayes Model\n",
      "Precision:\n",
      "[0.6666666666666666]\n",
      "Recall:\n",
      "[0.7777777777777778]\n",
      "F1 Score:\n",
      "[0.49122807017543857]\n",
      "Evaluating Decision Tree Model\n",
      "Precision:\n",
      "[0.3684210526315789]\n",
      "Recall:\n",
      "[0.5555555555555556]\n",
      "F1 Score:\n",
      "[0.6857142857142857]\n"
     ]
    }
   ],
   "source": [
    "naive_precision=[]\n",
    "naive_recall=[]\n",
    "naive_f1_score=[]\n",
    "\n",
    "dec_precision=[]\n",
    "dec_recall=[]\n",
    "dec_f1_score=[]\n",
    "\n",
    "# precision\n",
    "i=0\n",
    "while(i<5):\n",
    "    if(naive_tp[i]==0 and naive_fp[i]==0):\n",
    "        naive_precision.append(-1)\n",
    "    else:\n",
    "        naive_precision.append(naive_tp[i]/(naive_fp[i]+naive_tp[i]))\n",
    "    if(dec_tp[i]==0 and dec_fp[i]==0):\n",
    "        dec_precision.append(-1)\n",
    "    else:\n",
    "        dec_precision.append(dec_tp[i]/(dec_fp[i]+dec_tp[i]))\n",
    "    i+=1\n",
    "\n",
    "# recall\n",
    "i=0\n",
    "while(i<5):\n",
    "    if(naive_tp[i]==0 and naive_fn[i]==0):\n",
    "        naive_recall.append(-1)\n",
    "    else:\n",
    "        naive_recall.append(naive_tp[i]/(naive_fn[i]+naive_tp[i]))\n",
    "    if(dec_tp[i]==0 and dec_fn[i]==0):\n",
    "        dec_recall.append(-1)\n",
    "    else:\n",
    "        dec_recall.append(dec_tp[i]/(dec_fn[i]+dec_tp[i]))\n",
    "    i+=1\n",
    "\n",
    "# f1 score \n",
    "i=0\n",
    "while(i<5):\n",
    "    if(naive_tp[i]==0 and naive_fp[i]==0 and naive_fn[i]==0):\n",
    "        naive_f1_score.append(-1)\n",
    "    else:\n",
    "        naive_f1_score.append((2*naive_tp[i])/((2*naive_tp[i])+naive_fp[i]+naive_fn[i]))\n",
    "    if(dec_tp[i]==0 and dec_fp[i]==0 and dec_fn[i]==0):\n",
    "        dec_f1_score.append(-1)\n",
    "    else:\n",
    "        dec_f1_score.append((2*dec_tp[i])/((2*dec_tp[i])+dec_fp[i]+dec_fn[i]))\n",
    "    i+=1\n",
    "\n",
    "    \n",
    "# The matrix is square, with all correct classifications along the upper-left to lower-right diagonal, in other words, predicted vs actual \n",
    "#therefore, we are selecting these values only\n",
    "\n",
    "\n",
    "print(\"Evaluating Naive Bayes Model\")\n",
    "\n",
    "print(\"Precision:\")\n",
    "print(naive_precision[:1])\n",
    "print(\"Recall:\")\n",
    "print(naive_recall[3:4])\n",
    "print(\"F1 Score:\")\n",
    "print(naive_f1_score[3:4])\n",
    "\n",
    "print(\"Evaluating Decision Tree Model\")\n",
    "\n",
    "print(\"Precision:\")\n",
    "print(dec_precision[2:3])\n",
    "print(\"Recall:\")\n",
    "print(dec_recall[3:4])\n",
    "print(\"F1 Score:\")\n",
    "print(dec_f1_score[:1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best metric for this type of assignments is Recall as this is the fraction of the relevant information that are successfully retrieved (Wikipedia). The model that gives the higher Recall percentage is Naive Bayes, therefore, this model will be used for the second hotel "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "_______________________________________________________________________________________________________________________\n",
    "HOTEL 2: \n",
    "\n",
    "Amsterdam Court Hotel\n",
    "\n",
    "226 West 50th Street, New York City, NY 10019-6702\n",
    "\n",
    "Rating: 3.5\n",
    "_______________________________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Spent 10 days here over Christmas and New Year...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>Clean and comfortable. Staff was friendly enou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>We needed a last minute hotel for a last minut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>I do not recommend staying here. This hotel ha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Terrific location, European sized room, basic,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                             review\n",
       "0     4.0  Spent 10 days here over Christmas and New Year...\n",
       "1     4.0  Clean and comfortable. Staff was friendly enou...\n",
       "2     3.0  We needed a last minute hotel for a last minut...\n",
       "3     1.0  I do not recommend staying here. This hotel ha...\n",
       "4     5.0  Terrific location, European sized room, basic,..."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfe=pd.read_csv(\"Rivarola.Ester-A5_Hotel2.csv\",usecols=[0,1],names=[\"rating\",\"review\"],encoding = \"ISO-8859-1\")\n",
    "dfe.head(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stemmer = nltk.stem.SnowballStemmer('english')\n",
    "class StemmedTfidfVectorizer(TfidfVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer=super(TfidfVectorizer,self).build_analyzer()\n",
    "        return lambda doc:(english_stemmer.stem(w) for w in analyzer(doc))\n",
    "vectorizer=StemmedTfidfVectorizer(min_df=1,stop_words='english',decode_error='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we needed to import numpy again as otherwise, the it was overwriting the data for dataset1\n",
    "\n",
    "import numpy as np\n",
    "target=[]\n",
    "for i in dfe.rating:\n",
    "    if(i==1):\n",
    "        target.append(\"1\")\n",
    "    elif(i==2):\n",
    "        target.append(\"2\")\n",
    "    elif(i==3):\n",
    "        target.append(\"3\")\n",
    "    elif(i==4):\n",
    "        target.append(\"4\")\n",
    "    else:\n",
    "        target.append(\"5\")\n",
    "z=np.array(target)\n",
    "a=vectorizer.fit_transform(dfe.review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200,)\n",
      "(200, 1767)\n"
     ]
    }
   ],
   "source": [
    "print(z.shape)\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision-Naive Bayes\n",
      "[0.6666666666666666]\n",
      "Recall-Naive Bayes\n",
      "[0.5833333333333334]\n",
      "F1 Score-Naive Bayes\n",
      "[0.4307692307692308]\n"
     ]
    }
   ],
   "source": [
    "#80% for training - 20% for testing\n",
    "\n",
    "z_train,z_test,a_train,a_test=train_test_split(z,a,random_state=40)\n",
    "\n",
    "naive_precision1=[]\n",
    "naive_recall1=[]\n",
    "naive_f1_score1=[]\n",
    "\n",
    "dec_precision1=[]\n",
    "dec_recall1=[]\n",
    "dec_f1_score1=[]\n",
    "\n",
    "# precision \n",
    "i=0\n",
    "while(i<5):\n",
    "    if(naive_tp[i]==0 and naive_fp[i]==0):\n",
    "        naive_precision1.append(-1)\n",
    "    else:\n",
    "        naive_precision1.append(naive_tp[i]/(naive_fp[i]+naive_tp[i]))\n",
    "    if(dec_tp[i]==0 and dec_fp[i]==0):\n",
    "        dec_precision1.append(-1)\n",
    "    else:\n",
    "        dec_precision1.append(dec_tp[i]/(dec_fp[i]+dec_tp[i]))\n",
    "        i+=1\n",
    "\n",
    "    # recall\n",
    "i=0\n",
    "while(i<5):\n",
    "    if(naive_tp[i]==0 and naive_fn[i]==0):\n",
    "        naive_recall1.append(-1)\n",
    "    else:\n",
    "        naive_recall1.append(naive_tp[i]/(naive_fn[i]+naive_tp[i]))\n",
    "    if(dec_tp[i]==0 and dec_fn[i]==0):\n",
    "        dec_recall1.append(-1)\n",
    "    else:\n",
    "        dec_recall1.append(dec_tp[i]/(dec_fn[i]+dec_tp[i]))\n",
    "        i+=1\n",
    "\n",
    "    # f1 score\n",
    "i=0\n",
    "while(i<5):\n",
    "    if(naive_tp[i]==0 and naive_fp[i]==0 and naive_fn[i]==0):\n",
    "        naive_f1_score1.append(-1)\n",
    "    else:\n",
    "        naive_f1_score1.append((2*naive_tp[i])/((2*naive_tp[i])+naive_fp[i]+naive_fn[i]))\n",
    "    if(dec_tp[i]==0 and dec_fp[i]==0 and dec_fn[i]==0):\n",
    "        dec_f1_score1.append(-1)\n",
    "    else:\n",
    "        dec_f1_score1.append((2*dec_tp[i])/((2*dec_tp[i])+dec_fp[i]+dec_fn[i]))\n",
    "    i+=1\n",
    "\n",
    "print(\"Precision-Naive Bayes\")\n",
    "print(naive_precision1[:1])\n",
    "print(\"Recall-Naive Bayes\")\n",
    "print(naive_recall1[2:3])\n",
    "print(\"F1 Score-Naive Bayes\")\n",
    "print(naive_f1_score1[2:3])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall values for the second hotel decreased but it still above 50% which makes it useful "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
